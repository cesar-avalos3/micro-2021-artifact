def ignore_lines(file):
    # check the first 1000 lines, if the phrase "device__attribute_async_engine_count"
    # is found, else return -99
    # This phrase is always printed by nsight-compute.
    i = 0
    with open(file) as in_file:
        for line in in_file:
            if ("device__attribute_async_engine_count" in line):
                return i
            elif(i > 1000):
                return -99
            i += 1
            
# General open file function, takes in a nsight-compute csv filename, 
# returns a pandas table.
def open_file(filename):
    #print(filename)
    lines_to_ignore = ignore_lines(filename)
    if(lines_to_ignore == -99):
        lines_to_ignore = 0
    table = pd.read_csv(filename, skiprows=lines_to_ignore,low_memory=False)
    if(table.loc[0,'ID'] != 0.0):
        table = table.drop(0)
        table.index = range(len(table))
    # For certain systems nsight-compute prints
    # comma-deliniated numbers, e.g. 1,000 instead of 1000.
    # We need to get rid of that. 
    table = table.replace(',','', regex=True)
    return table

# Opens the cycles-profiled-only csvs generated by
# the nsight-compute utility, obtained using the 
# run_hw.py under the accel-sim utility.
def open_cycles(filename):
    #print(filename)
    lines_to_ignore = ignore_cycle_lines(filename)
    if(lines_to_ignore == -99):
        lines_to_ignore = 0
    table = pd.read_csv(filename, skiprows=lines_to_ignore,low_memory=False)
    return table

def ignore_cycle_lines(file):
    # check the first 1000 lines, if the phrase "Section Name" is not found
    # return -99. Same as ignore_lines above, but for the cycles-only version.
    i = 0
    with open(file) as in_file:
        for line in in_file:
            if ("Section Name" in line):
                return i
            elif(i > 1000):
                return -99
            i += 1

def generate_DF(table, appendable_columns=['Kernel Name', 'gpc__cycles_elapsed.avg', 'ID']):
    x_large = table.loc[:,agnostic_features].values
    x_large = StandardScaler().fit_transform(x_large)
    temp = table.loc[:,agnostic_features]
    if(True):
        for value in agnostic_features:
            if(temp[value].isnull().values.any()):
                print(value)
    for new_col in appendable_columns:
        temp = table[[new_col]]
        if "Name" not in new_col:
            temp = pd.to_numeric(pd.Series( table.loc[:,new_col] ))
        try:
            x_large = pd.concat([x_large, temp], axis = 1)
        except:
            x_large = pd.concat([pd.DataFrame(x_large), pd.DataFrame(temp)], axis = 1)
    return x_large

def generate_PCA(table, pca_variation=0.9995, appendable_columns=['Kernel Name', 'gpc__cycles_elapsed.avg', 'ID'], debug=False):
    x_large = table.loc[:,agnostic_features].values
    x_large = StandardScaler().fit_transform(x_large)
    temp = table.loc[:,agnostic_features]
    if(True):
        for value in agnostic_features:
            if(temp[value].isnull().values.any()):
                print(value)
    pca_components = pca_variation
    pca = PCA(pca_components)
    principalComponents_Large = pca.fit_transform(x_large)
    principalDf_Large = pd.DataFrame(data = principalComponents_Large, columns = ['principal component '+str(x+1) for x in range(pca.n_components_)])
    for new_col in appendable_columns:
        temp = table[[new_col]]
        if "Name" not in new_col:
            temp = pd.to_numeric(pd.Series( table.loc[:,new_col] ))
        principalDf_Large = pd.concat([principalDf_Large, temp], axis = 1)
    return principalDf_Large, principalComponents_Large

def open_all(profile_paths):
    Beeg_Table = {}
    list_of_apps = []
    for app in profile_paths:
        try:
            print(app)
            table = open_file(profile_paths[app])
            DF_Large, PC_Large = generate_PCA(table)
            results = kmeans_clustering(DF_Large, PC_Large)
            Beeg_Table[app] = results
            list_of_apps.append(app)
        except Exception as e:
            print(app)
            print(e)
            print("Has a problem")
    return Beeg_Table, list_of_apps

def process_all(Beeg_Table, list_of_apps, extra_archs=[''], min_error_arg = 0.05, all_paths_ampere = [], all_paths_turing = []):
    list_of_speedups = []
    list_of_errors = []
    best_choices_dict = {}
    dict_best_choices = {}
    for app in list_of_apps:
        min_error = 99
        index_min_error = 99
        min_error_speedup = 99
        group_counts_min = []
        kernel_ids_min = []
        first_error_less_than_4_percent = []
        first_error_less_than_3_percent = []
        first_error_less_than_2_percent = []
        for i in range(len(Beeg_Table[app]['errors'])):
            error = Beeg_Table[app]['errors'][i]
            #error = Beeg_Table[app]['center_choices_errors'][i]
            speedup = Beeg_Table[app]['speedups'][i]
            group_counts = Beeg_Table[app]['group_count'][i]
            #kernel_ids = Beeg_Table[app]['center_choices_id'][i]
            kernel_ids = Beeg_Table[app]['first_choices_id'][i]
            print("The error is: "+str(error))
            print("The speedup is: "+str(speedup))
            if(error < min_error):
                min_error = error
                index_min_error = i
                min_error_speedup = speedup
                group_counts_min = group_counts
                kernel_ids_min = kernel_ids
            if(error < min_error_arg):
                first_error_less_than_4_percent.append([error,i,speedup, group_counts, kernel_ids])
                if(error < min_error_arg/2.0):
                    first_error_less_than_3_percent.append([error,i,speedup])
                    if(error < min_error_arg/4.0):
                        first_error_less_than_2_percent.append([error,i,speedup])
        if(len(first_error_less_than_4_percent)==0):
            first_error_less_than_4_percent.append([min_error, index_min_error, min_error_speedup,group_counts_min, kernel_ids_min])
        list_of_speedups.append(first_error_less_than_4_percent[0][2])
        list_of_errors.append(first_error_less_than_4_percent[0][0])
        best_choices_dict[app] = [first_error_less_than_4_percent[0][4],
                                  first_error_less_than_4_percent[0][3],
                                  first_error_less_than_4_percent[0][2]]
        dict_best_choices[app] = {'kernel_ids':first_error_less_than_4_percent[0][4], 
                                  'group_counts': first_error_less_than_4_percent[0][3], 
                                  'speedup': first_error_less_than_4_percent[0][2], 
                                  'error': first_error_less_than_4_percent[0][0]}

        #print(best_choices_dict[app])

    extra_archs_results = {}
    turing_results = {}
    if('turing' in extra_archs):
        list_of_turing_apps = []
        list_of_turing_results = []
        list_of_turing_speedups = []
        list_of_turing_names = []
        list_of_turing_total_runtimes = []
        for app in all_paths_turing:
            #print(table)
            try:
                table = open_file(all_paths_turing[app])
                time = pd.to_numeric(table['gpc__cycles_elapsed.avg']).sum()
                DF_Large = generate_DF(table)
                list_of_turing_apps.append(app)
                temp_results = check_results(DF_Large,best_choices=best_choices_dict[app][0], group_counts=best_choices_dict[app][1])
                turing_results[app] = temp_results
                list_of_turing_results.append(temp_results)
                list_of_turing_speedups.append(np.sum(best_choices_dict[app][0])/temp_results[0])
                list_of_turing_names.append(app)
                list_of_turing_total_runtimes.append(time)
            except Exception as e:
                print(e)
                pass
        extra_archs_results['turing'] = turing_results
#        extra_archs_results['turing'] = {'results': list_of_turing_results, 'speedups': list_of_turing_speedups, 'names': list_of_turing_names, 'total_time':list_of_turing_total_runtimes}
            #print(check_results(DF_Large,best_choices=best_choices_dict[app][0], group_counts=best_choices_dict[app][1]))
            
    if('ampere' in extra_archs):
        list_of_ampere_apps = []
        list_of_ampere_results = []
        list_of_ampere_speedups = []
        list_of_ampere_names = []
        for app in all_paths_ampere:
            try:
                table = open_file(all_paths_ampere[app])
                DF_Large = generate_DF(table)
                list_of_ampere_apps.append(app)
                temp_results = check_results(DF_Large,best_choices=best_choices_dict[app][0], group_counts=best_choices_dict[app][1])
                list_of_ampere_results.append(temp_results)
                list_of_ampere_speedups.append(temp_results[0]/np.sum(best_choices_dict[app][0]))
                list_of_ampere_names.append(app)
            except:
                pass
        extra_archs_results['ampere'] = {'results': list_of_ampere_results, 'speedups': list_of_ampere_speedups, 'names': list_of_ampere_names}

    return best_choices_dict, list_of_errors, list_of_speedups, dict_best_choices, extra_archs_results